{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "506cbde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f028e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MLOps\\\\DataScienceProject2.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d029a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"e:/MLOps/DataScienceProject2.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "948dbdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\MLOps\\\\DataScienceProject2.0'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db69a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "# In dataclass we dont need to use self keyword\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e558a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DataScienceProject.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH, SCHEMA_FILE_PATH\n",
    "from src.DataScienceProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a398e8",
   "metadata": {},
   "source": [
    "### Explanation of `ConfigurationManager` Class\n",
    "\n",
    "The `ConfigurationManager` class helps organize and manage the settings needed for a data science project. Hereâ€™s how it works in simple terms:\n",
    "\n",
    "- **Initialization (`__init__` method):**\n",
    "    - It reads three configuration files: one for general settings, one for parameters, and one for schema (structure of data).\n",
    "    - It stores the information from these files so the rest of the project can use them easily.\n",
    "    - It also makes sure that the main folder for saving results (artifacts) exists.\n",
    "\n",
    "- **Getting Data Ingestion Settings (`get_data_ingestion_config` method):**\n",
    "    - This method looks at the part of the configuration that tells how to get the data (where to download it from, where to save it, etc.).\n",
    "    - It makes sure the folder for storing the raw data exists.\n",
    "    - It creates a simple object (`DataIngestionConfig`) that holds all the important details for getting the data, like the download link and file paths.\n",
    "    - This object is then returned so other parts of the project can use it to fetch and store data.\n",
    "\n",
    "In summary, this class makes it easy to read settings from files and prepare everything needed to start working with data, without having to manually set up folders or paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4d7623c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self,config_filepath= CONFIG_FILE_PATH,params_filepath= PARAMS_FILE_PATH,schema_filepath= SCHEMA_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)    \n",
    "        \n",
    "        create_directories([self.config.artifacts_root])\n",
    "        \n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir= Path(config.root_dir),\n",
    "            source_URL= config.source_URL,\n",
    "            local_data_file= Path(config.local_data_file),\n",
    "            unzip_dir= Path(config.unzip_dir)\n",
    "        )\n",
    "        \n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "366c529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from src.DataScienceProject import logger\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "567af6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Component - Data INgestion component\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config:DataIngestionConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    # Downloadig the zip file\n",
    "    def download_file(self):\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            filename,headers = request.urlretrieve(\n",
    "                url = self.config.source_URL,\n",
    "                filename = self.config.local_data_file\n",
    "            )\n",
    "            logger.info(f\"{filename} download! with following info: \\n{headers}\")\n",
    "        else:\n",
    "            logger.info(f\"file already exists\")\n",
    "    \n",
    "    def extract_zip_file(self):\n",
    "        \"\"\"\n",
    "        zip_file_path: str\n",
    "        Extracts the zip file into the data directory\n",
    "        Functions returns None\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        unzip_path = self.config.unzip_dir\n",
    "        os.makedirs(unzip_path, exist_ok = True)\n",
    "        \n",
    "        # Check if the file is actually a zip file\n",
    "        if str(self.config.local_data_file).endswith('.zip'):\n",
    "            with zipfile.ZipFile(self.config.local_data_file, \"r\") as zip_ref:\n",
    "                zip_ref.extractall(unzip_path)\n",
    "                logger.info(f\"Extracted zip file to {unzip_path}\")\n",
    "        else:\n",
    "            logger.info(f\"File {self.config.local_data_file} is not a zip file, skipping extraction\")\n",
    "            # For non-zip files like CSV, just log that they're ready to use\n",
    "            logger.info(f\"Data file is ready at: {self.config.local_data_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f9d9070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-31 23:08:04,889: INFO: common : yaml file: config\\config.yml loaded successfully]\n",
      "[2025-08-31 23:08:04,892: INFO: common : yaml file: params.yml loaded successfully]\n",
      "[2025-08-31 23:08:04,895: INFO: common : yaml file: schema.yml loaded successfully]\n",
      "[2025-08-31 23:08:04,896: INFO: common : created directory at : artifacts]\n",
      "[2025-08-31 23:08:04,898: INFO: common : created directory at : artifacts/data_ingestion]\n",
      "[2025-08-31 23:08:04,892: INFO: common : yaml file: params.yml loaded successfully]\n",
      "[2025-08-31 23:08:04,895: INFO: common : yaml file: schema.yml loaded successfully]\n",
      "[2025-08-31 23:08:04,896: INFO: common : created directory at : artifacts]\n",
      "[2025-08-31 23:08:04,898: INFO: common : created directory at : artifacts/data_ingestion]\n",
      "[2025-08-31 23:08:04,898: INFO: 2557496555 : file already exists]\n",
      "[2025-08-31 23:08:04,898: INFO: 2557496555 : File artifacts\\data_ingestion\\data.csv is not a zip file, skipping extraction]\n",
      "[2025-08-31 23:08:04,898: INFO: 2557496555 : Data file is ready at: artifacts\\data_ingestion\\data.csv]\n",
      "[2025-08-31 23:08:04,898: INFO: 2557496555 : file already exists]\n",
      "[2025-08-31 23:08:04,898: INFO: 2557496555 : File artifacts\\data_ingestion\\data.csv is not a zip file, skipping extraction]\n",
      "[2025-08-31 23:08:04,898: INFO: 2557496555 : Data file is ready at: artifacts\\data_ingestion\\data.csv]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.download_file()\n",
    "    data_ingestion.extract_zip_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe0b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Restart kernel and reimport everything\n",
    "# %reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
